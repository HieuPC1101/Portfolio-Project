"""
Module optimization_comparison.py
T·∫°o tab t·ªïng h·ª£p k·∫øt qu·∫£ t·ªëi ∆∞u h√≥a c·ªßa c√°c m√¥ h√¨nh ƒë·ªÉ so s√°nh v√† h·ªó tr·ª£ quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import logging

# Import utility functions
from utils.portfolio_utils import (
    normalize_metric,
    validate_result,
    calculate_max_drawdown_safe
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import UI styling
from utils.ui_styling import get_custom_css, create_metric_card, create_section_header


def calculate_portfolio_metrics(result):
    """
    T√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√° danh m·ª•c ƒë·∫ßu t∆∞.
    
    Args:
        result (dict): K·∫øt qu·∫£ t·ªëi ∆∞u h√≥a t·ª´ m·ªôt m√¥ h√¨nh
        
    Returns:
        dict: C√°c ch·ªâ s·ªë ƒë√°nh gi√°
    """
    metrics = {}
    
    # L·ª£i nhu·∫≠n k·ª≥ v·ªçng (%)
    metrics['expected_return'] = result.get('L·ª£i nhu·∫≠n k·ª≥ v·ªçng', 0) * 100
    
    # R·ªßi ro (ƒë·ªô l·ªách chu·∫©n) (%)
    metrics['volatility'] = result.get('R·ªßi ro (ƒê·ªô l·ªách chu·∫©n)', 0) * 100
    
    # T·ª∑ l·ªá Sharpe
    metrics['sharpe_ratio'] = result.get('T·ª∑ l·ªá Sharpe', 0)
    
    # S·ªë m√£ c·ªï phi·∫øu trong danh m·ª•c
    allocation = result.get('S·ªë m√£ c·ªï phi·∫øu c·∫ßn mua', {})
    metrics['num_stocks'] = len([k for k, v in allocation.items() if v > 0])
    
    # T·ªïng s·ªë l∆∞·ª£ng c·ªï phi·∫øu
    metrics['total_shares'] = sum(allocation.values())
    
    # S·ªë ti·ªÅn ƒë√£ ƒë·∫ßu t∆∞
    prices = result.get('Gi√° m√£ c·ªï phi·∫øu', {})
    total_invested = sum(allocation.get(ticker, 0) * prices.get(ticker, 0) 
                        for ticker in allocation.keys())
    metrics['total_invested'] = total_invested
    
    # S·ªë ti·ªÅn c√≤n l·∫°i
    metrics['leftover'] = result.get('S·ªë ti·ªÅn c√≤n l·∫°i', 0)
    
    # T·ª∑ l·ªá s·ª≠ d·ª•ng v·ªën (%)
    total_capital = total_invested + metrics['leftover']
    metrics['capital_utilization'] = (total_invested / total_capital * 100) if total_capital > 0 else 0
    
    # T·ª∑ l·ªá Return/Risk
    metrics['return_risk_ratio'] = (metrics['expected_return'] / metrics['volatility']) if metrics['volatility'] > 0 else 0
    
    # CVaR v√† CDaR n·∫øu c√≥
    metrics['cvar'] = result.get('R·ªßi ro CVaR', None)
    metrics['cdar'] = result.get('R·ªßi ro CDaR', None)
    
    # Maximum Drawdown (MDD) - S·ª≠ d·ª•ng utility function v·ªõi fallback an to√†n
    returns_data = result.get('ret_arr')
    metrics['max_drawdown'] = calculate_max_drawdown_safe(
        returns_data=returns_data,
        cdar=metrics['cdar'],
        volatility=metrics['volatility']
    )
    
    # M·ª©c ƒë·ªô ƒëa d·∫°ng h√≥a (Herfindahl Index)
    weights = result.get('Tr·ªçng s·ªë danh m·ª•c', {})
    if weights:
        weight_values = np.array(list(weights.values()))
        herfindahl = np.sum(weight_values ** 2)
        # Chuy·ªÉn ƒë·ªïi th√†nh ch·ªâ s·ªë ƒëa d·∫°ng h√≥a (1 = ƒëa d·∫°ng t·ªëi ƒëa, 0 = t·∫≠p trung)
        metrics['diversification_index'] = (1 - herfindahl) / (1 - 1/len(weights)) if len(weights) > 1 else 0
    else:
        metrics['diversification_index'] = 0
    
    return metrics


def precompute_all_metrics(results_dict):
    """
    Pre-compute metrics cho t·∫•t c·∫£ m√¥ h√¨nh m·ªôt l·∫ßn duy nh·∫•t.
    Tr√°nh t√≠nh to√°n l·∫∑p l·∫°i khi render nhi·ªÅu bi·ªÉu ƒë·ªì.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
                           {'T√™n m√¥ h√¨nh': result_dict}
    
    Returns:
        dict: {model_name: metrics_dict}
    
    Example:
        >>> results = {'Model A': {...}, 'Model B': {...}}
        >>> metrics_cache = precompute_all_metrics(results)
        >>> # S·ª≠ d·ª•ng cache thay v√¨ t√≠nh l·∫°i
        >>> model_a_metrics = metrics_cache['Model A']
    """
    metrics_cache = {}
    
    for model_name, result in results_dict.items():
        if result is None:
            logger.warning(f"Result for {model_name} is None, skipping")
            continue
        
        # Validate result tr∆∞·ªõc khi t√≠nh metrics
        if not validate_result(result):
            logger.warning(f"Result for {model_name} failed validation, skipping")
            continue
        
        try:
            metrics = calculate_portfolio_metrics(result)
            metrics_cache[model_name] = metrics
            logger.info(f"Pre-computed metrics for {model_name}")
        except Exception as e:
            logger.error(f"Failed to compute metrics for {model_name}: {e}")
            continue
    
    logger.info(f"Pre-computed metrics for {len(metrics_cache)}/{len(results_dict)} models")
    return metrics_cache


def create_comparison_table(results_dict, metrics_cache=None):
    """
    T·∫°o b·∫£ng so s√°nh c√°c m√¥ h√¨nh t·ªëi ∆∞u h√≥a.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
                           {'T√™n m√¥ h√¨nh': result_dict}
        metrics_cache (dict, optional): Pre-computed metrics cache
    
    Returns:
        pd.DataFrame: B·∫£ng so s√°nh
    """
    # N·∫øu kh√¥ng c√≥ cache, t√≠nh m·ªõi
    if metrics_cache is None:
        metrics_cache = precompute_all_metrics(results_dict)
    
    comparison_data = []
    
    for model_name, result in results_dict.items():
        if result is None or model_name not in metrics_cache:
            continue
        
        # S·ª≠ d·ª•ng metrics t·ª´ cache
        metrics = metrics_cache[model_name]
        
        comparison_data.append({
            'M√¥ h√¨nh': model_name,
            'L·ª£i nhu·∫≠n KV (%)': metrics['expected_return'],
            'R·ªßi ro - Std (%)': metrics['volatility'],
            'T·ª∑ l·ªá Sharpe': metrics['sharpe_ratio'],
            'Return/Risk': metrics['return_risk_ratio'],
            'Ch·ªâ s·ªë ƒëa d·∫°ng h√≥a': metrics['diversification_index'],
            'T·ª∑ l·ªá s·ª≠ d·ª•ng v·ªën (%)': metrics['capital_utilization'],
            'S·ªë m√£ CP': int(metrics['num_stocks']) if metrics['num_stocks'] else 0,
            'T·ªïng s·ªë c·ªï phi·∫øu ƒë·∫ßu t∆∞': int(metrics['total_shares']) if metrics['total_shares'] else 0,
            'V·ªën s·ª≠ d·ª•ng (VND)': float(metrics['total_invested']) if metrics['total_invested'] else 0.0,
            'V·ªën c√≤n l·∫°i (VND)': float(metrics['leftover']) if metrics['leftover'] else 0.0
        })
    
    return pd.DataFrame(comparison_data)


def highlight_best_values(df):
    """
    T√¥ m√†u ch·ªâ s·ªë t·ªët nh·∫•t trong b·∫£ng so s√°nh.
    
    Args:
        df (pd.DataFrame): B·∫£ng so s√°nh
    
    Returns:
        Styled DataFrame
    """
    styled = df.style
    
    # Format c√°c c·ªôt s·ªë
    format_dict = {
        'L·ª£i nhu·∫≠n KV (%)': '{:.2f}',
        'R·ªßi ro - Std (%)': '{:.2f}',
        'T·ª∑ l·ªá Sharpe': '{:.4f}',
        'Return/Risk': '{:.4f}',
        'Ch·ªâ s·ªë ƒëa d·∫°ng h√≥a': '{:.4f}',
        'T·ª∑ l·ªá s·ª≠ d·ª•ng v·ªën (%)': '{:.2f}',
        'V·ªën s·ª≠ d·ª•ng (VND)': '{:,.0f}',
        'V·ªën c√≤n l·∫°i (VND)': '{:,.0f}'
    }
    styled = styled.format(format_dict)
    
    # H√†m highlight MAX (gi√° tr·ªã cao = t·ªët)
    def highlight_max(col):
        is_max = col == col.max()
        return ['background-color: #90EE90; font-weight: bold' if v else '' for v in is_max]
    
    # H√†m highlight MIN (gi√° tr·ªã th·∫•p = t·ªët)
    def highlight_min(col):
        is_min = col == col.min()
        return ['background-color: #90EE90; font-weight: bold' if v else '' for v in is_min]
    
    # Highlight MAX cho c√°c ch·ªâ s·ªë cao = t·ªët
    max_cols = ['L·ª£i nhu·∫≠n KV (%)', 'T·ª∑ l·ªá Sharpe', 'Return/Risk', 
                'Ch·ªâ s·ªë ƒëa d·∫°ng h√≥a', 'T·ª∑ l·ªá s·ª≠ d·ª•ng v·ªën (%)']
    
    for col in max_cols:
        if col in df.columns:
            styled = styled.apply(highlight_max, subset=[col])
    
    # Highlight MIN cho r·ªßi ro (th·∫•p = t·ªët)
    min_cols = ['R·ªßi ro - Std (%)']
    for col in min_cols:
        if col in df.columns:
            styled = styled.apply(highlight_min, subset=[col])
    
    return styled


def plot_risk_return_comparison(results_dict, metrics_cache=None):
    """
    V·∫Ω bi·ªÉu ƒë·ªì so s√°nh r·ªßi ro - l·ª£i nhu·∫≠n c·ªßa c√°c m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
        metrics_cache (dict, optional): Pre-computed metrics cache
    """
    # N·∫øu kh√¥ng c√≥ cache, t√≠nh m·ªõi
    if metrics_cache is None:
        metrics_cache = precompute_all_metrics(results_dict)
    
    fig = go.Figure()
    
    for model_name in results_dict.keys():
        if model_name not in metrics_cache:
            continue
        
        metrics = metrics_cache[model_name]
        
        fig.add_trace(go.Scatter(
            x=[metrics['volatility']],
            y=[metrics['expected_return']],
            mode='markers+text',
            name=model_name,
            text=[model_name],
            textposition="top center",
            marker=dict(size=15, line=dict(width=2)),
            hovertemplate=f"<b>{model_name}</b><br>" +
                         f"L·ª£i nhu·∫≠n: {metrics['expected_return']:.2f}%<br>" +
                         f"R·ªßi ro: {metrics['volatility']:.2f}%<br>" +
                         f"Sharpe: {metrics['sharpe_ratio']:.4f}<extra></extra>"
        ))
    
    fig.update_layout(
        title="So s√°nh R·ªßi ro - L·ª£i nhu·∫≠n c√°c M√¥ h√¨nh",
        xaxis_title="R·ªßi ro (ƒê·ªô l·ªách chu·∫©n) %",
        yaxis_title="L·ª£i nhu·∫≠n k·ª≥ v·ªçng %",
        hovermode='closest',
        showlegend=True,
        height=500
    )
    
    st.plotly_chart(fig, width='stretch')


def plot_sharpe_comparison(results_dict, metrics_cache=None):
    """
    V·∫Ω bi·ªÉu ƒë·ªì c·ªôt so s√°nh t·ª∑ l·ªá Sharpe c·ªßa c√°c m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
        metrics_cache (dict, optional): Pre-computed metrics cache
    """
    # N·∫øu kh√¥ng c√≥ cache, t√≠nh m·ªõi
    if metrics_cache is None:
        metrics_cache = precompute_all_metrics(results_dict)
    
    model_names = []
    sharpe_ratios = []
    
    for model_name in results_dict.keys():
        if model_name not in metrics_cache:
            continue
        
        metrics = metrics_cache[model_name]
        model_names.append(model_name)
        sharpe_ratios.append(metrics['sharpe_ratio'])
    
    fig = go.Figure(data=[
        go.Bar(
            x=model_names,
            y=sharpe_ratios,
            text=[f"{sr:.4f}" for sr in sharpe_ratios],
            textposition='auto',
            marker_color='lightblue'
        )
    ])
    
    fig.update_layout(
        title="So s√°nh T·ª∑ l·ªá Sharpe",
        xaxis_title="M√¥ h√¨nh",
        yaxis_title="T·ª∑ l·ªá Sharpe",
        height=400
    )
    
    st.plotly_chart(fig, width='stretch')


def plot_allocation_comparison(results_dict):
    """
    V·∫Ω bi·ªÉu ƒë·ªì Stacked Bar Chart so s√°nh ph√¢n b·ªï t√†i s·∫£n c·ªßa c√°c m√¥ h√¨nh.
    D·ªÖ so s√°nh t·ª∑ tr·ªçng c·ªßa c√πng m√£ c·ªï phi·∫øu gi·ªØa c√°c m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
    """
    if not results_dict:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ so s√°nh ph√¢n b·ªï.")
        return
    
    # T·∫≠p h·ª£p t·∫•t c·∫£ c√°c tickers
    all_tickers = set()
    for result in results_dict.values():
        if result:
            weights = result.get('Tr·ªçng s·ªë danh m·ª•c', {})
            all_tickers.update(weights.keys())
    
    all_tickers = sorted(list(all_tickers))
    model_names = [name for name, result in results_dict.items() if result]
    
    if not all_tickers or not model_names:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ph√¢n b·ªï ƒë·ªÉ hi·ªÉn th·ªã.")
        return
    
    # T·∫°o Stacked Bar Chart
    fig = go.Figure()
    
    # Th√™m bar cho m·ªói ticker
    for ticker in all_tickers:
        weights_across_models = []
        for model_name in model_names:
            result = results_dict[model_name]
            weights = result.get('Tr·ªçng s·ªë danh m·ª•c', {})
            weight_pct = weights.get(ticker, 0) * 100
            weights_across_models.append(weight_pct)
        
        fig.add_trace(go.Bar(
            name=ticker,
            x=model_names,
            y=weights_across_models,
            text=[f"{w:.1f}%" if w > 0 else "" for w in weights_across_models],
            textposition='inside',
            hovertemplate=f"<b>{ticker}</b><br>" +
                         "M√¥ h√¨nh: %{x}<br>" +
                         "T·ª∑ tr·ªçng: %{y:.2f}%<extra></extra>"
        ))
    
    fig.update_layout(
        title="So s√°nh Ph√¢n b·ªï Tr·ªçng s·ªë Danh m·ª•c (Stacked Bar)",
        xaxis_title="M√¥ h√¨nh",
        yaxis_title="T·ª∑ tr·ªçng (%)",
        barmode='stack',
        height=500,
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.02
        )
    )
    
    st.plotly_chart(fig, width='stretch')


def plot_diversification_comparison(results_dict, metrics_cache=None):
    """
    V·∫Ω bi·ªÉu ƒë·ªì so s√°nh m·ª©c ƒë·ªô ƒëa d·∫°ng h√≥a c·ªßa c√°c m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
        metrics_cache (dict, optional): Pre-computed metrics cache
    """
    # N·∫øu kh√¥ng c√≥ cache, t√≠nh m·ªõi
    if metrics_cache is None:
        metrics_cache = precompute_all_metrics(results_dict)
    
    model_names = []
    diversification_scores = []
    num_stocks = []
    
    for model_name in results_dict.keys():
        if model_name not in metrics_cache:
            continue
        
        metrics = metrics_cache[model_name]
        model_names.append(model_name)
        diversification_scores.append(metrics['diversification_index'])
        num_stocks.append(metrics['num_stocks'])
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=("Ch·ªâ s·ªë ƒêa d·∫°ng h√≥a", "S·ªë l∆∞·ª£ng M√£ c·ªï phi·∫øu"),
        specs=[[{"type": "bar"}, {"type": "bar"}]]
    )
    
    # Ch·ªâ s·ªë ƒëa d·∫°ng h√≥a
    fig.add_trace(
        go.Bar(
            x=model_names,
            y=diversification_scores,
            text=[f"{ds:.4f}" for ds in diversification_scores],
            textposition='auto',
            marker_color='lightcoral',
            name='ƒêa d·∫°ng h√≥a'
        ),
        row=1, col=1
    )
    
    # S·ªë l∆∞·ª£ng m√£ c·ªï phi·∫øu
    fig.add_trace(
        go.Bar(
            x=model_names,
            y=num_stocks,
            text=num_stocks,
            textposition='auto',
            marker_color='lightyellow',
            name='S·ªë m√£ CP'
        ),
        row=1, col=2
    )
    
    fig.update_layout(
        height=400,
        showlegend=False
    )
    
    st.plotly_chart(fig, width='stretch')


def plot_radar_comparison(results_dict, metrics_cache=None):
    """
    V·∫Ω bi·ªÉu ƒë·ªì radar so s√°nh to√†n di·ªán c√°c m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
        metrics_cache (dict, optional): Pre-computed metrics cache
    """
    if len(results_dict) == 0:
        return
    
    # N·∫øu kh√¥ng c√≥ cache, t√≠nh m·ªõi
    if metrics_cache is None:
        metrics_cache = precompute_all_metrics(results_dict)
    
    if not metrics_cache:
        return
    
    fig = go.Figure()
    
    # L·∫•y t·∫•t c·∫£ metrics t·ª´ cache
    all_metrics = list(metrics_cache.values())
    
    
    # T√¨m min/max ƒë·ªÉ chu·∫©n h√≥a
    max_return = max(m['expected_return'] for m in all_metrics)
    min_return = min(m['expected_return'] for m in all_metrics)
    max_volatility = max(m['volatility'] for m in all_metrics)
    min_volatility = min(m['volatility'] for m in all_metrics)
    max_sharpe = max(m['sharpe_ratio'] for m in all_metrics)
    min_sharpe = min(m['sharpe_ratio'] for m in all_metrics)
    max_div = max(m['diversification_index'] for m in all_metrics)
    min_div = min(m['diversification_index'] for m in all_metrics)
    max_capital = max(m['capital_utilization'] for m in all_metrics)
    min_capital = min(m['capital_utilization'] for m in all_metrics)
    
    # S·ª≠ d·ª•ng utility function normalize_metric v·ªõi padding
    for model_name in metrics_cache.keys():
        metrics = metrics_cache[model_name]
        
        # Chu·∫©n h√≥a v·ªõi padding (volatility reverse v√¨ th·∫•p = t·ªët)
        norm_return = normalize_metric(metrics['expected_return'], min_return, max_return, reverse=False, padding=0.1)
        norm_volatility = normalize_metric(metrics['volatility'], min_volatility, max_volatility, reverse=True, padding=0.1)
        norm_sharpe = normalize_metric(metrics['sharpe_ratio'], min_sharpe, max_sharpe, reverse=False, padding=0.1)
        norm_div = normalize_metric(metrics['diversification_index'], min_div, max_div, reverse=False, padding=0.1)
        norm_capital = normalize_metric(metrics['capital_utilization'], min_capital, max_capital, reverse=False, padding=0.1)
        
        fig.add_trace(go.Scatterpolar(
            r=[norm_return, norm_volatility, norm_sharpe, norm_div, norm_capital],
            theta=['L·ª£i nhu·∫≠n', 'An to√†n<br>(Low Risk)', 'Sharpe Ratio', 'ƒêa d·∫°ng h√≥a', 'Hi·ªáu qu·∫£ v·ªën'],
            fill='toself',
            name=model_name,
            hovertemplate=f"<b>{model_name}</b><br>" +
                         "%{theta}: %{r:.1f}/100<extra></extra>"
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )
        ),
        showlegend=True,
        title="Bi·ªÉu ƒë·ªì Radar",
        height=500
    )
    
    st.plotly_chart(fig, width='stretch')


def display_detailed_allocation(results_dict):
    """
    Hi·ªÉn th·ªã b·∫£ng chi ti·∫øt ph√¢n b·ªï s·ªë l∆∞·ª£ng c·ªï phi·∫øu c·ªßa t·ª´ng m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
    """
    st.subheader("üìä Chi ti·∫øt Ph√¢n b·ªï S·ªë l∆∞·ª£ng C·ªï phi·∫øu")
    
    # T·∫°o DataFrame t·ªïng h·ª£p
    all_tickers = set()
    for result in results_dict.values():
        if result:
            all_tickers.update(result.get('S·ªë m√£ c·ªï phi·∫øu c·∫ßn mua', {}).keys())
    
    all_tickers = sorted(list(all_tickers))
    
    allocation_data = {'M√£ CP': all_tickers}
    
    for model_name, result in results_dict.items():
        if result is None:
            allocation_data[model_name] = ['-'] * len(all_tickers)
        else:
            allocation = result.get('S·ªë m√£ c·ªï phi·∫øu c·∫ßn mua', {})
            # Convert t·∫•t c·∫£ v·ªÅ string ƒë·ªÉ tr√°nh l·ªói Arrow serialization
            allocation_data[model_name] = [str(allocation.get(ticker, '-')) for ticker in all_tickers]
    
    df_allocation = pd.DataFrame(allocation_data)
    
    st.dataframe(df_allocation, width='stretch', height=400)


def display_weight_comparison(results_dict):
    """
    Hi·ªÉn th·ªã b·∫£ng so s√°nh tr·ªçng s·ªë c·ªßa t·ª´ng m√¥ h√¨nh.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
    """
    st.subheader("üìà So s√°nh Tr·ªçng s·ªë Danh m·ª•c (%)")
    
    # T·∫°o DataFrame t·ªïng h·ª£p
    all_tickers = set()
    for result in results_dict.values():
        if result:
            all_tickers.update(result.get('Tr·ªçng s·ªë danh m·ª•c', {}).keys())
    
    all_tickers = sorted(list(all_tickers))
    
    weight_data = {'M√£ CP': all_tickers}
    
    for model_name, result in results_dict.items():
        if result is None:
            weight_data[model_name] = ['-'] * len(all_tickers)
        else:
            weights = result.get('Tr·ªçng s·ªë danh m·ª•c', {})
            weight_data[model_name] = [f"{weights.get(ticker, 0)*100:.2f}%" if ticker in weights else '-' 
                                       for ticker in all_tickers]
    
    df_weights = pd.DataFrame(weight_data)
    
    st.dataframe(df_weights, width='stretch', height=400)


def provide_investment_recommendation(results_dict, metrics_cache=None):
    """
    ƒê∆∞a ra khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞ v·ªõi h·ªá th·ªëng ch·∫•m ƒëi·ªÉm chu·∫©n h√≥a (0-100).
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
        metrics_cache (dict, optional): Pre-computed metrics cache
    """
    st.markdown(create_section_header("H·ªá th·ªëng Khuy·∫øn ngh·ªã ƒê·∫ßu t∆∞", "üí°"), unsafe_allow_html=True)
    st.markdown("""
    <div style="background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); padding: 15px; border-radius: 10px; margin: 15px 0;">
        <p style="margin: 0; color: #1a73e8; font-weight: 600;">
            üéØ Ph√¢n t√≠ch d·ª±a tr√™n h·ªá th·ªëng ch·∫•m ƒëi·ªÉm ai chu·∫©n h√≥a, k·∫øt h·ª£p nhi·ªÅu ti√™u ch√≠ quan tr·ªçng ƒë·ªÉ ƒë∆∞a ra khuy·∫øn ngh·ªã t·ªët nh·∫•t.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    if not results_dict or all(r is None for r in results_dict.values()):
        st.warning("Ch∆∞a c√≥ k·∫øt qu·∫£ t·ªëi ∆∞u h√≥a ƒë·ªÉ ƒë∆∞a ra khuy·∫øn ngh·ªã.")
        return
    
    # N·∫øu kh√¥ng c√≥ cache, t√≠nh m·ªõi
    if metrics_cache is None:
        metrics_cache = precompute_all_metrics(results_dict)
    
    if not metrics_cache:
        st.warning("Kh√¥ng c√≥ m√¥ h√¨nh h·ª£p l·ªá ƒë·ªÉ ƒë√°nh gi√°.")
        return
    
    # 1. L·∫•y t·∫•t c·∫£ metrics t·ª´ cache
    all_metrics = list(metrics_cache.values())
    
    # 2. X√°c ƒë·ªãnh Min/Max cho chu·∫©n h√≥a
    min_return = min(m['expected_return'] for m in all_metrics)
    max_return = max(m['expected_return'] for m in all_metrics)
    min_volatility = min(m['volatility'] for m in all_metrics)
    max_volatility = max(m['volatility'] for m in all_metrics)
    min_sharpe = min(m['sharpe_ratio'] for m in all_metrics)
    max_sharpe = max(m['sharpe_ratio'] for m in all_metrics)
    min_div = min(m['diversification_index'] for m in all_metrics)
    max_div = max(m['diversification_index'] for m in all_metrics)
    min_capital = min(m['capital_utilization'] for m in all_metrics)
    max_capital = max(m['capital_utilization'] for m in all_metrics)
    
    # 2. T√≠nh ƒëi·ªÉm cho t·ª´ng m√¥ h√¨nh
    scores = {}
    score_details = []  # ƒê·ªÉ hi·ªÉn th·ªã b·∫£ng chi ti·∫øt
    
    for model_name in metrics_cache.keys():
        metrics = metrics_cache[model_name]
        
        # Chu·∫©n h√≥a t·ª´ng th√†nh ph·∫ßn (0-100) - S·ª≠ d·ª•ng utility function
        norm_sharpe = normalize_metric(metrics['sharpe_ratio'], min_sharpe, max_sharpe, reverse=False, padding=0)
        norm_return = normalize_metric(metrics['expected_return'], min_return, max_return, reverse=False, padding=0)
        norm_volatility = normalize_metric(metrics['volatility'], min_volatility, max_volatility, reverse=True, padding=0)
        norm_div = normalize_metric(metrics['diversification_index'], min_div, max_div, reverse=False, padding=0)
        norm_capital = normalize_metric(metrics['capital_utilization'], min_capital, max_capital, reverse=False, padding=0)
        
        # 5. T√≠nh ƒêi·ªÉm T·ªïng h·ª£p (Weighted Score)
        total_score = (
            norm_sharpe * 0.4 +      # 40% Sharpe
            norm_return * 0.3 +      # 30% Return
            norm_div * 0.2 +         # 20% Diversification
            norm_capital * 0.1       # 10% Capital Efficiency
        )
        
        scores[model_name] = {
            'total_score': total_score,
            'sharpe': metrics['sharpe_ratio'],
            'return': metrics['expected_return'],
            'risk': metrics['volatility'],
            'diversification': metrics['diversification_index'],
            'capital_util': metrics['capital_utilization']
        }
        
        score_details.append({
            'M√¥ h√¨nh': model_name,
            'Return (raw)': f"{metrics['expected_return']:.2f}%",
            'Sharpe (raw)': f"{metrics['sharpe_ratio']:.4f}",
            'Risk (raw)': f"{metrics['volatility']:.2f}%",
            'Div (raw)': f"{metrics['diversification_index']:.4f}",
            'Capital (raw)': f"{metrics['capital_utilization']:.2f}%",
            'Score Return': f"{norm_return:.1f}",
            'Score Sharpe': f"{norm_sharpe:.1f}",
            'Score Risk': f"{norm_volatility:.1f}",
            'Score Div': f"{norm_div:.1f}",
            'Score Capital': f"{norm_capital:.1f}",
            'T·ªïng ƒëi·ªÉm': f"{total_score:.2f}"
        })
    
    # 6. Hi·ªÉn th·ªã b·∫£ng chi ti·∫øt ƒëi·ªÉm s·ªë (minh b·∫°ch h√≥a)
    with st.expander("üìä Chi ti·∫øt B·∫£ng ƒêi·ªÉm - C√°ch t√≠nh ƒêi·ªÉm s·ªë", expanded=False):
        st.markdown("""
        **Ph∆∞∆°ng ph√°p ch·∫•m ƒëi·ªÉm chu·∫©n h√≥a (Normalized Scoring)**
        
        1. **Thu th·∫≠p d·ªØ li·ªáu th√¥**: L·∫•y c√°c ch·ªâ s·ªë t·ª´ t·∫•t c·∫£ m√¥ h√¨nh
        2. **Chu·∫©n h√≥a v·ªÅ thang 0-100**: 
           - C√¥ng th·ª©c: `Score = ((Value - Min) / (Max - Min)) √ó 100`
           - ƒê·∫£o ng∆∞·ª£c cho R·ªßi ro: `Score = ((Max - Value) / (Max - Min)) √ó 100`
        3. **T√≠nh T·ªïng ƒëi·ªÉm**: `Sharpe√ó40% + Return√ó30% + Div√ó20% + Capital√ó10%`
        
        **B·∫£ng chi ti·∫øt c√°c th√†nh ph·∫ßn ƒëi·ªÉm:**
        """)
        
        df_scores = pd.DataFrame(score_details)
        st.dataframe(df_scores, width='stretch', height=300)
        
        st.caption("üí° C·ªôt 'Score' l√† ƒëi·ªÉm chu·∫©n h√≥a (0-100), c·ªôt 'raw' l√† gi√° tr·ªã g·ªëc")
    
    # S·∫Øp x·∫øp theo ƒëi·ªÉm t·ªïng h·ª£p
    sorted_models = sorted(scores.items(), key=lambda x: x[1]['total_score'], reverse=True)
    
    # Hi·ªÉn th·ªã top 3 khuy·∫øn ngh·ªã v·ªõi styled header
    st.markdown("### üèÜ Top 3 Ph∆∞∆°ng √°n ƒê∆∞·ª£c Khuy·∫øn ngh·ªã")
    st.markdown("""
    <div style="background: linear-gradient(135deg, #e0f7fa 0%, #b2ebf2 100%); 
                padding: 12px 20px; 
                border-radius: 8px; 
                border-left: 4px solid #00acc1;
                margin-bottom: 20px;">
        <p style="margin: 0; color: #006064; font-size: 14px;">
            üí° <strong>C√¥ng th·ª©c t√≠nh ƒëi·ªÉm (Thang 0-100):</strong> Sharpe (40%) + L·ª£i nhu·∫≠n (30%) + ƒêa d·∫°ng h√≥a (20%) + Hi·ªáu qu·∫£ v·ªën (10%)
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    for rank, (model_name, score_data) in enumerate(sorted_models[:3], 1):
        medal = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â"
        
        # T·ª± ƒë·ªông m·ªü r·ªông top 1
        is_expanded = (rank == 1)
        with st.expander(f"{medal} #{rank}: **{model_name}** (ƒêi·ªÉm: {score_data['total_score']:.2f})", expanded=is_expanded):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("T·ª∑ l·ªá Sharpe", f"{score_data['sharpe']:.4f}")
                st.metric("L·ª£i nhu·∫≠n KV", f"{score_data['return']:.2f}%")
            
            with col2:
                st.metric("R·ªßi ro (Std)", f"{score_data['risk']:.2f}%")
                st.metric("Return/Risk", f"{score_data['return']/score_data['risk']:.4f}")
            
            with col3:
                st.metric("ƒêa d·∫°ng h√≥a", f"{score_data['diversification']:.4f}")
                st.metric("S·ª≠ d·ª•ng v·ªën", f"{score_data['capital_util']:.1f}%")
            
            # ƒê∆∞a ra nh·∫≠n x√©t
            if rank == 1:
                st.success(f"‚úÖ **{model_name}** l√† l·ª±a ch·ªçn t·ªët nh·∫•t v·ªõi hi·ªáu su·∫•t t·ªïng h·ª£p cao nh·∫•t.")
            
            # Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh
            strengths = []
            if score_data['sharpe'] == max(s['sharpe'] for s in scores.values()):
                strengths.append("T·ª∑ l·ªá Sharpe cao nh·∫•t")
            if score_data['return'] == max(s['return'] for s in scores.values()):
                strengths.append("L·ª£i nhu·∫≠n k·ª≥ v·ªçng cao nh·∫•t")
            if score_data['risk'] == min(s['risk'] for s in scores.values()):
                strengths.append("R·ªßi ro th·∫•p nh·∫•t")
            if score_data['diversification'] == max(s['diversification'] for s in scores.values()):
                strengths.append("ƒêa d·∫°ng h√≥a t·ªët nh·∫•t")
            
            if strengths:
                st.info(f"**ƒêi·ªÉm m·∫°nh:** {', '.join(strengths)}")
    
    # H∆∞·ªõng d·∫´n l·ª±a ch·ªçn
    st.markdown("---")
    st.markdown("### üìù H∆∞·ªõng d·∫´n L·ª±a ch·ªçn")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **üéØ Ch·ªçn m√¥ h√¨nh ph√π h·ª£p v·ªõi m·ª•c ti√™u:**
        - **Max Sharpe / Markowitz**: C√¢n b·∫±ng l·ª£i nhu·∫≠n v√† r·ªßi ro
        - **Min Volatility**: ∆Øu ti√™n an to√†n, √≠t bi·∫øn ƒë·ªông
        - **Min CVaR / Min CDaR**: Ph√≤ng ng·ª´a t·ªïn th·∫•t c·ª±c ƒëoan
        - **HRP**: ƒêa d·∫°ng h√≥a th√¥ng minh, ph√¢n t√°n r·ªßi ro
        """)
    
    with col2:
        st.markdown("""
        **üîç C√°c ti√™u ch√≠ quan tr·ªçng:**
        - **T·ª∑ l·ªá Sharpe**: Hi·ªáu su·∫•t ƒëi·ªÅu ch·ªânh theo r·ªßi ro
        - **Return/Risk**: L·ª£i nhu·∫≠n tr√™n m·ªói ƒë∆°n v·ªã r·ªßi ro
        - **ƒêa d·∫°ng h√≥a**: M·ª©c ƒë·ªô ph√¢n t√°n ƒë·∫ßu t∆∞
        - **S·ª≠ d·ª•ng v·ªën**: Hi·ªáu qu·∫£ t·∫≠n d·ª•ng ngu·ªìn v·ªën
        """)


def render_optimization_comparison_tab(results_dict):
    """
    Render tab t·ªïng h·ª£p k·∫øt qu·∫£ t·ªëi ∆∞u h√≥a.
    
    Args:
        results_dict (dict): Dictionary ch·ª©a k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh
                           {'T√™n m√¥ h√¨nh': result_dict}
    """
    st.title("üìä T·ªïng h·ª£p & So s√°nh K·∫øt qu·∫£ T·ªëi ∆∞u h√≥a")
    
    if not results_dict or all(r is None for r in results_dict.values()):
        st.info("""
        üëã Ch√†o m·ª´ng ƒë·∫øn v·ªõi tab **T·ªïng h·ª£p K·∫øt qu·∫£**!
        
        üìå **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:**
        1. Ch·ªçn tab **"T·ª± ch·ªçn m√£ c·ªï phi·∫øu"** ho·∫∑c **"H·ªá th·ªëng ƒë·ªÅ xu·∫•t m√£ c·ªï phi·∫øu t·ª± ƒë·ªông"**
        2. Ch·∫°y c√°c m√¥ h√¨nh t·ªëi ∆∞u h√≥a (Markowitz, Max Sharpe, Min Volatility, v.v.)
        3. K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông l∆∞u v√† hi·ªÉn th·ªã ·ªü ƒë√¢y ƒë·ªÉ so s√°nh
        
        üí° Tab n√†y gi√∫p b·∫°n:
        - So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh
        - Ph√¢n t√≠ch r·ªßi ro - l·ª£i nhu·∫≠n
        - ƒê∆∞a ra quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞ t·ªëi ∆∞u
        """)
        return
    
    # L·ªçc c√°c k·∫øt qu·∫£ h·ª£p l·ªá
    valid_results = {k: v for k, v in results_dict.items() if v is not None}
    
    if not valid_results:
        st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ t·ªëi ∆∞u h√≥a n√†o ƒë·ªÉ hi·ªÉn th·ªã.")
        return
    
    
    # Inject custom CSS for better styling
    st.markdown(get_custom_css(), unsafe_allow_html=True)
    
    # Pre-compute t·∫•t c·∫£ metrics m·ªôt l·∫ßn duy nh·∫•t (Performance Optimization)
    logger.info("Pre-computing metrics for all models...")
    metrics_cache = precompute_all_metrics(valid_results)
    logger.info(f"Successfully cached metrics for {len(metrics_cache)} models")
    
    # Summary metrics cards with gradients
    st.markdown("### üìà T·ªïng quan Nhanh")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(
            create_metric_card("S·ªë m√¥ h√¨nh", len(valid_results), "purple"),
            unsafe_allow_html=True
        )
    
    with col2:
        all_metrics = list(metrics_cache.values())
        avg_return = sum(m['expected_return'] for m in all_metrics) / len(all_metrics) if all_metrics else 0
        st.markdown(
            create_metric_card("L·ª£i nhu·∫≠n TB", f"{avg_return:.1f}%", "pink"),
            unsafe_allow_html=True
        )
    
    with col3:
        avg_sharpe = sum(m['sharpe_ratio'] for m in all_metrics) / len(all_metrics) if all_metrics else 0
        st.markdown(
            create_metric_card("Sharpe TB", f"{avg_sharpe:.3f}", "blue"),
            unsafe_allow_html=True
        )
    
    with col4:
        avg_stocks = sum(m['num_stocks'] for m in all_metrics) / len(all_metrics) if all_metrics else 0
        st.markdown(
            create_metric_card("S·ªë m√£ TB", f"{avg_stocks:.1f}", "green"),
            unsafe_allow_html=True
        )
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Tab con cho c√°c ph·∫ßn kh√°c nhau
    tab1, tab2, tab3 = st.tabs([
        "üìã B·∫£ng So s√°nh T·ªïng quan",
        "üìä Bi·ªÉu ƒë·ªì Ph√¢n t√≠ch",
        "üí° Khuy·∫øn ngh·ªã ƒê·∫ßu t∆∞"
    ])
    
    with tab1:
        st.markdown("### üìã B·∫£ng So s√°nh C√°c Ch·ªâ s·ªë Ch√≠nh")
        comparison_df = create_comparison_table(valid_results, metrics_cache)
        
        # Hi·ªÉn th·ªã b·∫£ng v·ªõi highlight
        styled_df = highlight_best_values(comparison_df)
        st.dataframe(styled_df, width='stretch', height=400)
        
        st.markdown("""
        **üìå Ch√∫ th√≠ch:**
        - <span style="background-color: #90EE90; font-weight: bold; padding: 2px 6px;">M√†u xanh ƒë·∫≠m</span>: Gi√° tr·ªã t·ªët nh·∫•t trong c·ªôt
        - **L·ª£i nhu·∫≠n KV**: L·ª£i nhu·∫≠n k·ª≥ v·ªçng h√†ng nƒÉm (c√†ng cao c√†ng t·ªët)
        - **R·ªßi ro - Std**: ƒê·ªô l·ªách chu·∫©n - bi·∫øn ƒë·ªông gi√° (c√†ng th·∫•p c√†ng an to√†n)
        - **T·ª∑ l·ªá Sharpe**: Hi·ªáu su·∫•t ƒëi·ªÅu ch·ªânh r·ªßi ro (c√†ng cao c√†ng t·ªët)
        - **Return/Risk**: T·ª∑ l·ªá l·ª£i nhu·∫≠n/r·ªßi ro tr·ª±c ti·∫øp (c√†ng cao c√†ng t·ªët)
        - **Ch·ªâ s·ªë ƒëa d·∫°ng h√≥a**: 0-1, v·ªõi 1 l√† ƒëa d·∫°ng ho√†n h·∫£o (c√†ng cao c√†ng ph√¢n t√°n)
        """, unsafe_allow_html=True)
        
        # N√∫t download
        csv = comparison_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="üì• T·∫£i xu·ªëng b·∫£ng so s√°nh (CSV)",
            data=csv,
            file_name="so_sanh_toi_uu.csv",
            mime="text/csv"
        )
    
    with tab2:
        st.markdown("### üìä Bi·ªÉu ƒë·ªì Ph√¢n t√≠ch So s√°nh")
        
        # Bi·ªÉu ƒë·ªì Radar t·ªïng quan
        st.markdown("#### Bi·ªÉu ƒë·ªì Radar")
        plot_radar_comparison(valid_results, metrics_cache)
        
        st.markdown("---")
        
        # R·ªßi ro - L·ª£i nhu·∫≠n
        st.markdown("#### üìà R·ªßi ro - L·ª£i nhu·∫≠n")
        plot_risk_return_comparison(valid_results, metrics_cache)
        
        st.markdown("---")
        st.markdown("‚óºÔ∏è### üìä So s√°nh Chi ti·∫øt theo Ch·ªâ s·ªë")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**‚ö° T·ª∑ l·ªá Sharpe**")
            st.caption("Hi·ªáu su·∫•t ƒëi·ªÅu ch·ªânh r·ªßi ro (c√†ng cao c√†ng t·ªët)")
            plot_sharpe_comparison(valid_results, metrics_cache)
        
        with col2:
            st.markdown("**üéØ M·ª©c ƒë·ªô ƒêa d·∫°ng h√≥a**")
            st.caption("Ch·ªâ s·ªë ƒëa d·∫°ng h√≥a & s·ªë l∆∞·ª£ng m√£ c·ªï phi·∫øu")
            plot_diversification_comparison(valid_results, metrics_cache)
        
        # Ph√¢n b·ªï tr·ªçng s·ªë
        st.markdown("---")
        st.markdown("####  Ph√¢n b·ªï Tr·ªçng s·ªë Danh m·ª•c")
        plot_allocation_comparison(valid_results)
        
        # Chi ti·∫øt ph√¢n b·ªï
        st.markdown("---")
        with st.expander("üîç Xem Chi ti·∫øt Tr·ªçng s·ªë & S·ªë l∆∞·ª£ng C·ªï phi·∫øu", expanded=False):
            st.info("üìå B·∫£ng chi ti·∫øt ph√¢n b·ªï c·ªï phi·∫øu cho t·ª´ng m√¥ h√¨nh")
            col_a, col_b = st.columns(2)
            with col_a:
                display_weight_comparison(valid_results)
            with col_b:
                display_detailed_allocation(valid_results)
    
    with tab3:
        # Khuy·∫øn ngh·ªã
        provide_investment_recommendation(valid_results, metrics_cache)
